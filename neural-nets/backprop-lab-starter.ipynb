{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69b3ed-5f7e-44a3-9ed9-1520ecc416d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data specifically cubic data, y= x^{3}- 3x + 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "x_data = np.arange(-3, 3, .1)\n",
    "y_numeric = x_data ** 3 - 3 * x_data + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe39454-89a7-4eb9-9916-9778915f963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data\n",
    "\n",
    "plt.plot(x_data, y_numeric, -3, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e3947-ad2c-4142-8abb-8cd079908437",
   "metadata": {},
   "source": [
    "# Neural Network 1: Regression, no hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22610dfa-d192-4c90-a1f3-e3c5f08d7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network 1, no hidden layer, regression (should duplicate linear regression)\n",
    "\n",
    "# Activation function is identity function (not sigmoid)\n",
    "# Loss function is squared error\n",
    "\n",
    "X_train = np.array(x_data).reshape((-1, 1))\n",
    "y_train = y_numeric\n",
    "\n",
    "W = np.array([[.1]])\n",
    "b = np.array([.2])\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_deriv(z):\n",
    "    if z >= 0: \n",
    "        return 1 \n",
    "    else: return 0\n",
    "\n",
    "def compute_loss(a, y):\n",
    "    return .5 * (a - y) ** 2\n",
    "\n",
    "def compute_cost(X_data, y_data, W, b):\n",
    "    m = X_data.shape[0] # number of data points\n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        y_hat = run_model(X_data[i], W, b)\n",
    "        y = y_data[i]\n",
    "        cost += compute_loss(y_hat, y)\n",
    "    total_cost = (1 / (2 * m)) * cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def run_model(x, W, b):\n",
    "    return x @ W + b\n",
    "\n",
    "def loss_deriv(a, y):\n",
    "    return a-y\n",
    "\n",
    "def backward_prop(x, y, W, b):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1746561-d059-45fa-b288-ce2533bfae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(X_train[0], W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18e597-fa5b-4c53-9137-ee01d51c6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost(X_train, y_train, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666f609-63f7-47ea-b462-19ee1691edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_prop(X_train[0], y_train[0], W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bd5d5-1700-4ce7-80f8-e1a8d2f2d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent:\n",
    "\n",
    "W = np.array([[-.1]])\n",
    "b = np.array([.2])\n",
    "ALPHA = .0006\n",
    "\n",
    "J_sequence = []\n",
    "\n",
    "#print(\"x train is\", X_train)\n",
    "#print(\"y train is\", y_train)\n",
    "\n",
    "for ctr in range(0, 6000):\n",
    "    \n",
    "    grads = [0,0]\n",
    "    for i in range(X_train.shape[0]):   # m\n",
    "        dL_dw0, dL_db = backward_prop(X_train[i], y_train[i], W, b)\n",
    "        grads[0] += dL_dw0\n",
    "        grads[1] += dL_db   \n",
    "    W[0][0] -= ALPHA * grads[0]/X_train.shape[1]\n",
    "    b[0] -= ALPHA * grads[1]/X_train.shape[1]\n",
    "                              \n",
    "    J_sequence.append(compute_cost(X_train, y_train, W, b))\n",
    "    \n",
    "print(\"Final W:\", W, b)\n",
    "print(\"Final cost:\", compute_cost(X_train, y_train, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c900d3-10aa-4efb-bb8c-54bd1962b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the cost as a function of number of iterations of the\n",
    "# gradient descent algorithm.\n",
    "\n",
    "plt.scatter(range(0, len(J_sequence)), J_sequence)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bec448-3a04-4882-a730-bd01904ec746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate original plot\n",
    "\n",
    "y_predicted = [run_model([x], W, b) for x in x_data]\n",
    "plt.plot(x_data, y_numeric, -3, 3)\n",
    "plt.plot(x_data, y_predicted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecb861-b930-40ba-b44f-6ed040a753c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify this matches linear regression\n",
    "\n",
    "# Download and install scikit-learn if not already done:\n",
    "%pip install scikit-learn\n",
    "\n",
    "# Import the logistic regression functionality from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a logistic regression model and train it on our training data:\n",
    "model = LinearRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "\n",
    "# model.coef_ contains the w vector that this linear regression model was able to find\n",
    "\n",
    "print(\"w found through scikit-learn:\", model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2032f-5c40-4fa5-89c3-39a37ebd81f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e28b73c-b2bb-47a5-ac8a-48e541f27e35",
   "metadata": {},
   "source": [
    "# Neural Network 2, 1 hidden layer with 2 neurons, regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa8e48-eadd-414e-a496-2482bbff0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network 1, no hidden layer, regression (should duplicate linear regression)\n",
    "\n",
    "# Activation function is identity function (not sigmoid)\n",
    "# Loss function is squared error\n",
    "\n",
    "X_train = np.array(x_data).reshape((-1, 1))\n",
    "y_train = y_numeric\n",
    "\n",
    "W1 = np.array()\n",
    "W2 = np.array()\n",
    "b1 = np.array()\n",
    "b2 = np.array()\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_deriv(z):\n",
    "    if z >= 0: \n",
    "        return 1 \n",
    "    else: return 0\n",
    "\n",
    "def compute_loss(a, y):\n",
    "    return .5 * (a - y) ** 2\n",
    "\n",
    "def compute_cost(X_data, y_data, W1, b1, W2, b2)\n",
    "    m = X_data.shape[0] # number of data points\n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        y_hat = run_model(X_data[i], W1, b1, W2, b2)\n",
    "        y = y_data[i]\n",
    "        cost += compute_loss(y_hat, y)\n",
    "    total_cost = (1 / (2 * m)) * cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def run_model(x, W1, b1, W2, b2):\n",
    "    return x @ W + b\n",
    "\n",
    "def loss_deriv(a, y):\n",
    "    return a-y\n",
    "\n",
    "def backward_prop(x, y, W1, b1, W2, b2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8179e64-a316-46e9-8b29-7ea049346651",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(X_train[0], W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a209fe-9c42-43cd-9450-b595f5f6fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost(X_train, y_train, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e998ca3-8a0e-4644-b533-418c0a079759",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_prop(X_train[0], y_train[0], W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00611a3f-3ee1-497d-867e-65ea3ff16491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent:\n",
    "\n",
    "W = np.array([[-.1]])\n",
    "b = np.array([.2])\n",
    "ALPHA = .0006\n",
    "\n",
    "J_sequence = []\n",
    "\n",
    "#print(\"x train is\", X_train)\n",
    "#print(\"y train is\", y_train)\n",
    "\n",
    "for ctr in range(0, 6000):\n",
    "\n",
    "    grads = [0,0]\n",
    "    for i in range(X_train.shape[0]):   # m\n",
    "       \n",
    "        dL_dw0, dL_db = backward_prop(X_train[i], y_train[i], W1, b1, W2, b2)\n",
    "        grads[0] += dL_dw0\n",
    "        grads[1] += dL_db   \n",
    "    W[0][0] -= ALPHA * grads[0]/X_train.shape[1]\n",
    "    b[0] -= ALPHA * grads[1]/X_train.shape[1]\n",
    "                              \n",
    "    J_sequence.append(compute_cost(X_train, y_train, W1, b1, W2, b2))\n",
    "    \n",
    "print(\"Final W:\", W1, b1, W2, b2)\n",
    "print(\"Final cost:\", compute_cost(X_train, y_train, W1, b1, W2, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4b7c6-36a8-4d66-ae5a-067f1d06dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the cost as a function of number of iterations of the\n",
    "# gradient descent algorithm.\n",
    "\n",
    "plt.scatter(range(0, len(J_sequence)), J_sequence)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f97f13-5495-4e7a-b246-98f40da8d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate original plot\n",
    "print(W1, b1, W2, b2)\n",
    "y_predicted = [make_prediction([1, x], W1, b1, W2, b2) for x in x_data]\n",
    "plt.plot(x_data, y_numeric, -3, 3)\n",
    "plt.plot(x_data, y_predicted)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
